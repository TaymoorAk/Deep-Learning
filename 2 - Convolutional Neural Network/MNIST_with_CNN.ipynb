{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MNIST with CNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gF7rCB6lRZOY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Network**"
      ]
    },
    {
      "metadata": {
        "id": "VnIgKuPNPlj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHi-9uMkRU1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VT0dktmLRs2W",
        "colab_type": "code",
        "outputId": "6571f8a7-24df-4519-85d4-7707f4bb359f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-1a516c502833>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WBGxV4jMR7Ym",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**\n"
      ]
    },
    {
      "metadata": {
        "id": "90F6o4auXxey",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to help intialize random weights for fully connected or covolutional layers, we leave the shape attribute as a parameter for this.\n"
      ]
    },
    {
      "metadata": {
        "id": "tZPYsWYrR4jK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_weights(shape):\n",
        "  init_random_dist = tf.truncated_normal(shape, stddev = 0.1)\n",
        "  return tf.Variable(init_random_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7G_o8KFqYMhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Same as init_weights but for the biases"
      ]
    },
    {
      "metadata": {
        "id": "ygC7lOp-SUrx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def init_bias(shape):\n",
        "  init_bias_vals = tf.constant(0.1, shape = shape)\n",
        "  return tf.Variable(init_bias_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8Y8QAFAYw4j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating 2D convolutional neural net.**"
      ]
    },
    {
      "metadata": {
        "id": "ALbbwducYu3G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFVIfvX6ZJlc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating a max pooling layer , using built in TF functions"
      ]
    },
    {
      "metadata": {
        "id": "TQRBf2wcZIdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def max_pool_2by2(x):\n",
        "  return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IM6i6ub9ZkfN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using the conv2d function, we'll return an actual convolutional layer here that uses as Relu activation function."
      ]
    },
    {
      "metadata": {
        "id": "cFyqRxaoZjdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolutional_layer(input_x, shape):\n",
        "  W = init_weights(shape)\n",
        "  b = init_bias([shape[3]])\n",
        "  return tf.nn.relu(conv2d(input_x, W) + b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2kmAn8saUxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a normal fully connected layer"
      ]
    },
    {
      "metadata": {
        "id": "UunORbUoaTwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normal_full_layer(input_layer, size):\n",
        "  input_size = int(input_layer.get_shape()[1])\n",
        "  W = init_weights([input_size , size])\n",
        "  b = init_bias([size])\n",
        "  return tf.matmul(input_layer , W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jiqJkZa9bT0q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Placeholders**"
      ]
    },
    {
      "metadata": {
        "id": "4iDWS3W1a2qA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.float32, shape = [None, 784])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KcJ_nsbwbe3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_true = tf.placeholder(tf.float32, shape = [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KS1MboCXbmas",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Layers**"
      ]
    },
    {
      "metadata": {
        "id": "QNB90IGVblfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_image = tf.reshape(x, [-1, 28, 28, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77OMs3iHbwf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZkRTFpmcADN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ss8pF-wVdBDK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Flattening**"
      ]
    },
    {
      "metadata": {
        "id": "Ldfz60ixdEV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9VocyIAadd8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqQgzYcfdwej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = normal_full_layer(full_one_dropout,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laLJr4kQd-QC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loss Function**"
      ]
    },
    {
      "metadata": {
        "id": "wpCxDGaQd84F",
        "colab_type": "code",
        "outputId": "700d1489-6f47-4da1-9cf7-5682082a83b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Am8Uy3jufDpT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "metadata": {
        "id": "dcQoBc8-eUjZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001)\n",
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkMaraVAfinY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Initialize Variables**"
      ]
    },
    {
      "metadata": {
        "id": "Sv3s9DWbfhSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WT-2SNtZfuFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SESSION**"
      ]
    },
    {
      "metadata": {
        "id": "ug_L3Z_TftQ5",
        "colab_type": "code",
        "outputId": "c7c71d12-f6d5-4b13-d057-bca738596fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1173
        }
      },
      "cell_type": "code",
      "source": [
        "steps = 5000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        \n",
        "        batch_x , batch_y = mnist.train.next_batch(50)\n",
        "        \n",
        "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
        "        \n",
        "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
        "        if i%100 == 0:\n",
        "            \n",
        "            print('Currently on step {}'.format(i))\n",
        "            print('Accuracy is:')\n",
        "            # Test the Train Model\n",
        "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "\n",
        "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
        "            print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9831\n",
            "\n",
            "\n",
            "Currently on step 3700\n",
            "Accuracy is:\n",
            "0.9833\n",
            "\n",
            "\n",
            "Currently on step 3800\n",
            "Accuracy is:\n",
            "0.9857\n",
            "\n",
            "\n",
            "Currently on step 3900\n",
            "Accuracy is:\n",
            "0.9831\n",
            "\n",
            "\n",
            "Currently on step 4000\n",
            "Accuracy is:\n",
            "0.9836\n",
            "\n",
            "\n",
            "Currently on step 4100\n",
            "Accuracy is:\n",
            "0.9858\n",
            "\n",
            "\n",
            "Currently on step 4200\n",
            "Accuracy is:\n",
            "0.9834\n",
            "\n",
            "\n",
            "Currently on step 4300\n",
            "Accuracy is:\n",
            "0.9843\n",
            "\n",
            "\n",
            "Currently on step 4400\n",
            "Accuracy is:\n",
            "0.986\n",
            "\n",
            "\n",
            "Currently on step 4500\n",
            "Accuracy is:\n",
            "0.986\n",
            "\n",
            "\n",
            "Currently on step 4600\n",
            "Accuracy is:\n",
            "0.9847\n",
            "\n",
            "\n",
            "Currently on step 4700\n",
            "Accuracy is:\n",
            "0.9857\n",
            "\n",
            "\n",
            "Currently on step 4800\n",
            "Accuracy is:\n",
            "0.9843\n",
            "\n",
            "\n",
            "Currently on step 4900\n",
            "Accuracy is:\n",
            "0.9863\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "87lZJoMSm_ND",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}